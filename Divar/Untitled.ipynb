{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('DMC-Train.parquet', engine='pyarrow')\n",
    "valid = pd.read_parquet('DMC-phase2-validation.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "df['jsoned_post_data'] = df['post_data'].apply(json.loads)\n",
    "valid['jsoned_post_data'] = valid['post_data'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['jsoned_post_data'].apply(lambda x: x['new_price'] if 'new_price' in x else -1)\n",
    "valid['price'] = valid['jsoned_post_data'].apply(lambda x: x['new_price'] if 'new_price' in x else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand_model'] = df['jsoned_post_data'].apply(lambda x: x['brand_model'] if 'brand_model' in x else '')\n",
    "valid['brand_model'] = valid['jsoned_post_data'].apply(lambda x: x['brand_model'] if 'brand_model' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_numbers = []\n",
    "\n",
    "for i in range(1,10): \n",
    "    for j in range(5,11):\n",
    "        bad_numbers.append(int(str(i)*j))\n",
    "        \n",
    "a = '1234567890'\n",
    "b = '987654321'\n",
    "for i in range(7,11): \n",
    "    for j in range(0,11-i):\n",
    "        bad_numbers.append(int(a[j:j+i]))\n",
    "        \n",
    "for i in range(7,10): \n",
    "    for j in range(0,10-i):\n",
    "        bad_numbers.append(int(b[j:j+i]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_in_bad_numbers'] = df['price'].apply(lambda x: 1 if x in bad_numbers else 0)\n",
    "valid['price_in_bad_numbers'] = valid['price'].apply(lambda x: 1 if x in bad_numbers else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df['jsoned_post_data'].apply(lambda x: x['category'] if 'category' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['jsoned_post_data'].apply(lambda x: x['description'])\n",
    "valid['description'] = valid['jsoned_post_data'].apply(lambda x: x['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['jsoned_post_data'].apply(lambda x: x['title'] if 'title' in x else '')\n",
    "valid['title'] = valid['jsoned_post_data'].apply(lambda x: x['title'] if 'title' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['jsoned_post_data'].apply(lambda x: x['year'] if 'year' in x else '')\n",
    "valid['year'] = valid['jsoned_post_data'].apply(lambda x: x['year'] if 'year' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_data</th>\n",
       "      <th>review_label</th>\n",
       "      <th>reject_reason_id</th>\n",
       "      <th>jsoned_post_data</th>\n",
       "      <th>price</th>\n",
       "      <th>brand_model</th>\n",
       "      <th>price_in_bad_numbers</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "      <th>body_status</th>\n",
       "      <th>review_label_encoded</th>\n",
       "      <th>purchase_in_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cb000599-2ee2-42c1-9f0e-32cfeb940398</td>\n",
       "      <td>{\"body_status\": \"witout-color\", \"brand\": \"\\u06...</td>\n",
       "      <td>accept</td>\n",
       "      <td>0</td>\n",
       "      <td>{'body_status': 'witout-color', 'brand': 'تیبا...</td>\n",
       "      <td>103000000</td>\n",
       "      <td>Tiba Sedan SX</td>\n",
       "      <td>0</td>\n",
       "      <td>بدون رنگ،کم کارکرد</td>\n",
       "      <td>تیبا صندوق‌دار SX، مدل ۱۳۹۷</td>\n",
       "      <td>۱۳۹۷</td>\n",
       "      <td>تیبا::Tiba</td>\n",
       "      <td>witout-color</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12063741-6634-444b-befa-0be4c95c2b42</td>\n",
       "      <td>{\"body_status\": \"witout-color\", \"brand\": \"\\u06...</td>\n",
       "      <td>reject</td>\n",
       "      <td>13</td>\n",
       "      <td>{'body_status': 'witout-color', 'brand': 'لیفا...</td>\n",
       "      <td>26700000</td>\n",
       "      <td>Lifan X60 manual</td>\n",
       "      <td>0</td>\n",
       "      <td>اسفند 95\\nبیمه بدنه کلا تخفیف \\nمانیتور 10 این...</td>\n",
       "      <td>لیفان X60 دنده‌ای، مدل ۱۳۹۵</td>\n",
       "      <td>۱۳۹۵</td>\n",
       "      <td>لیفان::Lifan</td>\n",
       "      <td>witout-color</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>81c93119-5c06-412f-80aa-363ddb0ebc33</td>\n",
       "      <td>{\"body_status\": \"witout-color\", \"brand\": \"\\u06...</td>\n",
       "      <td>accept</td>\n",
       "      <td>0</td>\n",
       "      <td>{'body_status': 'witout-color', 'brand': 'پژو ...</td>\n",
       "      <td>190000000</td>\n",
       "      <td>Peugeot 405 SLX</td>\n",
       "      <td>0</td>\n",
       "      <td>بیمه شخص ثالث،بیمه بدنه،دارای روکش صندلی و کفی...</td>\n",
       "      <td>پژو 405 SLX بنزینی، مدل ۱۳۹۹</td>\n",
       "      <td>۱۳۹۹</td>\n",
       "      <td>پژو ۴۰۵::Peugeot 405</td>\n",
       "      <td>witout-color</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b5a5bfa7-03be-408b-b4d9-bca26c0ca59b</td>\n",
       "      <td>{\"brand\": \"\\u0633\\u0627\\u06cc\\u0631\", \"brand_m...</td>\n",
       "      <td>accept</td>\n",
       "      <td>0</td>\n",
       "      <td>{'brand': 'سایر', 'brand_model': 'Dena basic 1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Dena basic 1700cc</td>\n",
       "      <td>0</td>\n",
       "      <td>■نمایندگی رجبی کد ۵٣٠٧٣٢\\n□فروش نقدی ■ شعبه تو...</td>\n",
       "      <td>دنا DENA معمولی EF7 صفر // مدل 99 خشک آماده تحویل</td>\n",
       "      <td>۱۳۹۹</td>\n",
       "      <td>سایر</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3414e920-dfaf-44a8-9853-0b03d66e9e2a</td>\n",
       "      <td>{\"body_status\": \"intact\", \"brand\": \"\\u067e\\u06...</td>\n",
       "      <td>reject</td>\n",
       "      <td>12</td>\n",
       "      <td>{'body_status': 'intact', 'brand': 'پژو ۲۰۶‍ ص...</td>\n",
       "      <td>240000000</td>\n",
       "      <td>Peugeot 206 SD V8</td>\n",
       "      <td>0</td>\n",
       "      <td>ماشین صفر برج ۹سال ۹۹ سند رهن ایران خودرو</td>\n",
       "      <td>پژو 206 SD V8، مدل ۱۳۹۹</td>\n",
       "      <td>۱۳۹۹</td>\n",
       "      <td>پژو ۲۰۶‍ صندوق‌دار::Peugeot 206</td>\n",
       "      <td>intact</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                post_id  \\\n",
       "0  cb000599-2ee2-42c1-9f0e-32cfeb940398   \n",
       "1  12063741-6634-444b-befa-0be4c95c2b42   \n",
       "2  81c93119-5c06-412f-80aa-363ddb0ebc33   \n",
       "3  b5a5bfa7-03be-408b-b4d9-bca26c0ca59b   \n",
       "4  3414e920-dfaf-44a8-9853-0b03d66e9e2a   \n",
       "\n",
       "                                           post_data review_label  \\\n",
       "0  {\"body_status\": \"witout-color\", \"brand\": \"\\u06...       accept   \n",
       "1  {\"body_status\": \"witout-color\", \"brand\": \"\\u06...       reject   \n",
       "2  {\"body_status\": \"witout-color\", \"brand\": \"\\u06...       accept   \n",
       "3  {\"brand\": \"\\u0633\\u0627\\u06cc\\u0631\", \"brand_m...       accept   \n",
       "4  {\"body_status\": \"intact\", \"brand\": \"\\u067e\\u06...       reject   \n",
       "\n",
       "   reject_reason_id                                   jsoned_post_data  \\\n",
       "0                 0  {'body_status': 'witout-color', 'brand': 'تیبا...   \n",
       "1                13  {'body_status': 'witout-color', 'brand': 'لیفا...   \n",
       "2                 0  {'body_status': 'witout-color', 'brand': 'پژو ...   \n",
       "3                 0  {'brand': 'سایر', 'brand_model': 'Dena basic 1...   \n",
       "4                12  {'body_status': 'intact', 'brand': 'پژو ۲۰۶‍ ص...   \n",
       "\n",
       "       price        brand_model  price_in_bad_numbers  \\\n",
       "0  103000000      Tiba Sedan SX                     0   \n",
       "1   26700000   Lifan X60 manual                     0   \n",
       "2  190000000    Peugeot 405 SLX                     0   \n",
       "3         -1  Dena basic 1700cc                     0   \n",
       "4  240000000  Peugeot 206 SD V8                     0   \n",
       "\n",
       "                                         description  \\\n",
       "0                                 بدون رنگ،کم کارکرد   \n",
       "1  اسفند 95\\nبیمه بدنه کلا تخفیف \\nمانیتور 10 این...   \n",
       "2  بیمه شخص ثالث،بیمه بدنه،دارای روکش صندلی و کفی...   \n",
       "3  ■نمایندگی رجبی کد ۵٣٠٧٣٢\\n□فروش نقدی ■ شعبه تو...   \n",
       "4          ماشین صفر برج ۹سال ۹۹ سند رهن ایران خودرو   \n",
       "\n",
       "                                               title  year  \\\n",
       "0                        تیبا صندوق‌دار SX، مدل ۱۳۹۷  ۱۳۹۷   \n",
       "1                        لیفان X60 دنده‌ای، مدل ۱۳۹۵  ۱۳۹۵   \n",
       "2                       پژو 405 SLX بنزینی، مدل ۱۳۹۹  ۱۳۹۹   \n",
       "3  دنا DENA معمولی EF7 صفر // مدل 99 خشک آماده تحویل  ۱۳۹۹   \n",
       "4                            پژو 206 SD V8، مدل ۱۳۹۹  ۱۳۹۹   \n",
       "\n",
       "                             brand   body_status  review_label_encoded  \\\n",
       "0                       تیبا::Tiba  witout-color                     0   \n",
       "1                     لیفان::Lifan  witout-color                     1   \n",
       "2             پژو ۴۰۵::Peugeot 405  witout-color                     0   \n",
       "3                             سایر                                   0   \n",
       "4  پژو ۲۰۶‍ صندوق‌دار::Peugeot 206        intact                     1   \n",
       "\n",
       "   purchase_in_title  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'] = df['jsoned_post_data'].apply(lambda x: x['brand'] if 'brand' in x else '')\n",
    "valid['brand'] = valid['jsoned_post_data'].apply(lambda x: x['brand'] if 'brand' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_status'] = df['jsoned_post_data'].apply(lambda x: x['body_status'] if 'body_status' in x else '')\n",
    "valid['body_status'] = valid['jsoned_post_data'].apply(lambda x: x['body_status'] if 'body_status' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['year'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "valid['year'] = valid['year'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "df['brand_model'] = df['brand_model'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "valid['brand_model'] = valid['brand_model'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "df['brand'] = df['brand'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "valid['brand'] = valid['brand'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import persian_normal as pn\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en', 'fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "valid['description'] = valid['description'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "valid['title'] = valid['title'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# pipeline for text data\n",
    "text_features = ['description','title']\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('vect', CountVectorizer()), ('tfidf', TfidfTransformer())\n",
    "])\n",
    "\n",
    "# pipeline for categorical data\n",
    "categorical_features = ['year','brand','brand_model','body_status']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# you can add other transformations for other data types\n",
    "\n",
    "# combine preprocessing with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_transformer, text_features[0]),\n",
    "        ('text2', text_transformer, text_features[1]),\n",
    "# #         ('text3', text_transformer, text_features[2]),\n",
    "# #         ('text4', text_transformer, text_features[3]),\n",
    "# #         ('text5', text_transformer, text_features[4])\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# add model to be part of pipeline  \n",
    "clf_pipe =  Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                    (\"model\", LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=0.9))\n",
    "                        (\"model\", ComplementNB(alpha=0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reject_reason_13'] = 0\n",
    "df.loc[df['reject_reason_id']==13,'reject_reason_13'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "# le.fit(list(df['brand_model'])+list(valid['brand_model']))\n",
    "le.fit(df['review_label'])\n",
    "df['review_label_encoded'] = le.transform(df['review_label'])\n",
    "# valid['review_label_encoded'] = le.transform(valid['review_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_purchase(title):\n",
    "    m = re.search('خرید', title)\n",
    "    if m:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['purchase_in_title'] = df['title'].apply(lambda x: extract_purchase(x))\n",
    "valid['purchase_in_title'] = valid['title'].apply(lambda x: extract_purchase(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['price','price_in_bad_numbers','year','description','title','brand','brand_model','purchase_in_title','body_status']], df['review_label_encoded'], test_size=0.25, random_state=42, stratify=df['review_label_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405271,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8505221631236869\n"
     ]
    }
   ],
   "source": [
    "clf_pipe.fit(X_train, y_train)\n",
    "# valid['predictions'] = clf_pipe.predict_proba(X_test)[:,0]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, clf_pipe.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8893672957215453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, clf_pipe.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "clf_pipe.fit(df[['price','price_in_bad_numbers','year','description','title','brand','brand_model','purchase_in_title','body_status']], df['review_label_encoded'])\n",
    "valid['predictions'] = clf_pipe.predict_proba(valid[['price','price_in_bad_numbers','year','description','title','brand','brand_model','purchase_in_title','body_status']])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipe.fit(df[['price','brand_model','price_in_bad_numbers','description','title','year','brand']], df['review_label_encoded'])\n",
    "valid['predictions'] = clf_pipe.predict_proba(valid[['price','brand_model','price_in_bad_numbers','description','title','year','brand']])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = valid[['post_id','predictions']]\n",
    "res.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['predictions'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected13 = df[df['reject_reason_id']==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rejected13 = rejected13[['price','description','title','brand_model']].groupby('price').count().sort_values('description',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected = df[df['review_label']=='reject']\n",
    "groupedrejected = rejected.groupby(by='reject_reason_id').count().sort_values('description',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedrejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected12 = df[df['reject_reason_id']==12]\n",
    "# grouped_rejected12 = rejected12[['price','description','title','brand_model']].groupby('price').count().sort_values('description',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rejected12 = rejected12[rejected12['purchase_in_description']==1].groupby('body_status').count().sort_values('description',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_accepted = accepted[accepted['purchase_in_description']==1].groupby('body_status').count().sort_values('description',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rejected12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected12.iloc[0]['jsoned_post_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_purchase(description_title):\n",
    "    m = re.search('سند', description_title)\n",
    "    n = re.search('رهن', description_title)\n",
    "#     o = re.search('1400|۱۴۰۰', description_title)\n",
    "    if m and n:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "rejected12['purchase_in_description'] = rejected12['description'].apply(lambda x: extract_purchase(x))\n",
    "accepted['purchase_in_description'] = accepted['description'].apply(lambda x: extract_purchase(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted[accepted['purchase_in_description']==1].iloc[8]['jsoned_post_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected12[rejected12['purchase_in_description']==1].iloc[0]['jsoned_post_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected163.iloc[12]['jsoned_post_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected163 = df[df['reject_reason_id']==163]\n",
    "rejected163.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = df[df['review_label']=='accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted.iloc[0]['jsoned_post_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_description_year_brand_brand_model\"] = df[\"title\"]+\" \"+ df[\"description\"]+\" \"+ df[\"year\"]+\" \"+df[\"brand\"]+\" \"+ df[\"brand_model\"]\n",
    "valid[\"title_description_year_brand_brand_model\"] = valid[\"title\"]+\" \"+ valid[\"description\"]+\" \"+ valid[\"year\"]+\" \"+valid[\"brand\"]+\" \"+ valid[\"brand_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import persian_normal as pn\n",
    "\n",
    "df['title_description_year_brand_brand_model'] = df['title_description_year_brand_brand_model'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en', 'fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))\n",
    "\n",
    "\n",
    "\n",
    "valid['title_description_year_brand_brand_model'] = valid['title_description_year_brand_brand_model'].apply(lambda x: pn.persian_pre_process(x,\n",
    "                        for_view=False,\n",
    "                        print_log=False,\n",
    "                        ok_characters=['fa', 'en','fa_digits', 'en_digits'],\n",
    "                        special_characters=[],\n",
    "                        digits_format='No_Change', \n",
    "                        nim_fasele_action='Space', \n",
    "                        enter_action='Space',\n",
    "                        stop_words=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = valid[['post_id','title_description_year_brand_brand_model']]\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[['post_id','title_description_year_brand_brand_model','review_label']]\n",
    "train.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
